{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset with inital features"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Dataset, Datastore, Workspace\r\n",
        "\r\n",
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "qualitydf = Dataset.get_by_name(workspace=ws,name=\"iiot_quality_featured_data\").to_pandas_dataframe()\r\n",
        "print(\"Rows => {0}\".format(qualitydf.shape[0]))\r\n",
        "print(\"Columns => {0}\".format(qualitydf.shape[1]))\r\n",
        "qualitydf.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Rows => 7711\nColumns => 20\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "   Quality       S16       S20       S19       S18       S29          S41  \\\n0        1  22.02698  33.14618  35.47309  31.48723  7.497666  7221.264648   \n1        1  22.02698  33.14618  35.47309  31.31926  7.491282  7213.028320   \n2        1  22.36291  32.97821  35.47309  31.65519  7.484899  7229.500977   \n3        1  22.19494  32.97821  35.47309  31.48723  7.500858  7213.028320   \n4        1  22.02698  32.97821  35.47309  31.65519  7.497666  7229.500977   \n\n     S9   S10    S8   S11       S14       S13       S28       S15       S26  \\\n0  36.1  39.5  27.6  21.9  2089.468  2046.699  26.79577  943.1278  31.57756   \n1  35.9  39.4  27.7  21.8  2069.875  2052.430  26.97901  930.0323  32.33240   \n2  35.9  39.5  28.1  21.9  2075.162  2060.232  26.99349  930.1899  32.49136   \n3  35.9  39.6  28.4  21.9  2137.928  2046.037  27.02537  943.1278  31.77274   \n4  36.1  39.6  28.8  22.1  2090.136  2033.450  27.14663  943.4471  31.68100   \n\n    S33        S7        S3       S39  \n0  40.0  23.57390  29.04669  5773.366  \n1  40.0  23.60346  28.67866  5773.366  \n2  40.0  23.57944  28.74189  5773.366  \n3  40.0  23.60447  27.57296  5773.366  \n4  40.0  23.64226  28.34144  5789.014  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Quality</th>\n      <th>S16</th>\n      <th>S20</th>\n      <th>S19</th>\n      <th>S18</th>\n      <th>S29</th>\n      <th>S41</th>\n      <th>S9</th>\n      <th>S10</th>\n      <th>S8</th>\n      <th>S11</th>\n      <th>S14</th>\n      <th>S13</th>\n      <th>S28</th>\n      <th>S15</th>\n      <th>S26</th>\n      <th>S33</th>\n      <th>S7</th>\n      <th>S3</th>\n      <th>S39</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>22.02698</td>\n      <td>33.14618</td>\n      <td>35.47309</td>\n      <td>31.48723</td>\n      <td>7.497666</td>\n      <td>7221.264648</td>\n      <td>36.1</td>\n      <td>39.5</td>\n      <td>27.6</td>\n      <td>21.9</td>\n      <td>2089.468</td>\n      <td>2046.699</td>\n      <td>26.79577</td>\n      <td>943.1278</td>\n      <td>31.57756</td>\n      <td>40.0</td>\n      <td>23.57390</td>\n      <td>29.04669</td>\n      <td>5773.366</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>22.02698</td>\n      <td>33.14618</td>\n      <td>35.47309</td>\n      <td>31.31926</td>\n      <td>7.491282</td>\n      <td>7213.028320</td>\n      <td>35.9</td>\n      <td>39.4</td>\n      <td>27.7</td>\n      <td>21.8</td>\n      <td>2069.875</td>\n      <td>2052.430</td>\n      <td>26.97901</td>\n      <td>930.0323</td>\n      <td>32.33240</td>\n      <td>40.0</td>\n      <td>23.60346</td>\n      <td>28.67866</td>\n      <td>5773.366</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>22.36291</td>\n      <td>32.97821</td>\n      <td>35.47309</td>\n      <td>31.65519</td>\n      <td>7.484899</td>\n      <td>7229.500977</td>\n      <td>35.9</td>\n      <td>39.5</td>\n      <td>28.1</td>\n      <td>21.9</td>\n      <td>2075.162</td>\n      <td>2060.232</td>\n      <td>26.99349</td>\n      <td>930.1899</td>\n      <td>32.49136</td>\n      <td>40.0</td>\n      <td>23.57944</td>\n      <td>28.74189</td>\n      <td>5773.366</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>22.19494</td>\n      <td>32.97821</td>\n      <td>35.47309</td>\n      <td>31.48723</td>\n      <td>7.500858</td>\n      <td>7213.028320</td>\n      <td>35.9</td>\n      <td>39.6</td>\n      <td>28.4</td>\n      <td>21.9</td>\n      <td>2137.928</td>\n      <td>2046.037</td>\n      <td>27.02537</td>\n      <td>943.1278</td>\n      <td>31.77274</td>\n      <td>40.0</td>\n      <td>23.60447</td>\n      <td>27.57296</td>\n      <td>5773.366</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>22.02698</td>\n      <td>32.97821</td>\n      <td>35.47309</td>\n      <td>31.65519</td>\n      <td>7.497666</td>\n      <td>7229.500977</td>\n      <td>36.1</td>\n      <td>39.6</td>\n      <td>28.8</td>\n      <td>22.1</td>\n      <td>2090.136</td>\n      <td>2033.450</td>\n      <td>27.14663</td>\n      <td>943.4471</td>\n      <td>31.68100</td>\n      <td>40.0</td>\n      <td>23.64226</td>\n      <td>28.34144</td>\n      <td>5789.014</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the data for model evaluation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = qualitydf.drop(['Quality'], axis=1)   # select all sensor values\r\n",
        "y = qualitydf[\"Quality\"]  # select the target column to predict\r\n",
        "\r\n",
        "# Split data into train(70%) and test(30%) datasets\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=0,stratify=y)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build baseline model "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\r\n",
        "from lightgbm import LGBMClassifier\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "# Replace null values with \"median\" and normalize all numeric values using MinMaxScaler\r\n",
        "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', MinMaxScaler())])\r\n",
        "transformations = ColumnTransformer(transformers=[('num', numeric_transformer, X.columns)])\r\n",
        "\r\n",
        "# Build classifier pipeline with preprocessing steps as above, and logistic regression as the model\r\n",
        "# Only use training dataset for build the model\r\n",
        "classifierPipeline = Pipeline(steps=[('preprocessor', transformations),('classifier', LogisticRegression())])\r\n",
        "model = classifierPipeline.fit(X_train, y_train)\r\n",
        "\r\n",
        "# Run the model and extract predictions\r\n",
        "y_pred = classifierPipeline.predict(X_test)\r\n",
        "y_pred_train = classifierPipeline.predict(X_train)\r\n",
        "\r\n",
        "# Score the model against true values\r\n",
        "print('Training set score: {:.4f}'.format(classifierPipeline.score(X_train, y_train)))\r\n",
        "print('Test set score: {:.4f}'.format(classifierPipeline.score(X_test, y_test)))\r\n",
        "\r\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training set score: 0.8205\nTest set score: 0.8202\n              precision    recall  f1-score   support\n\n           0       1.00      0.00      0.00       417\n           1       0.82      1.00      0.90      1897\n\n    accuracy                           0.82      2314\n   macro avg       0.91      0.50      0.45      2314\nweighted avg       0.85      0.82      0.74      2314\n\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try multiple models and compare all the scores\r\n",
        "\r\n",
        "In general we are looking for a model with high \"precision\" and high \"recall\". Depending on the risk appetite of the business and the consequences of the actions that we can recommend based on the predictions, we may choose to focus on specific evaluation metrics and thresholds. \r\n",
        "\r\n",
        "See [Classification metrics](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml?msclkid=a25fa0facff911ecae2ae07854ffb705#classification-metrics) for more details"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "classifierList = [DecisionTreeClassifier(), RandomForestClassifier(),LGBMClassifier(), \r\n",
        "                  AdaBoostClassifier(), GradientBoostingClassifier(), \r\n",
        "                  LogisticRegression(), RidgeClassifier(), SGDClassifier()]\r\n",
        "\r\n",
        "# Try multiple classifiers\r\n",
        "for currentClassifier in classifierList:\r\n",
        "    currentPipeline = Pipeline(steps=[('preprocessor', transformations),('classifier', currentClassifier)])\r\n",
        "    model = currentPipeline.fit(X_train, y_train)\r\n",
        "    y_pred = currentPipeline.predict(X_test)\r\n",
        "    y_pred_train = currentPipeline.predict(X_train)\r\n",
        "    print(type(currentClassifier).__name__)\r\n",
        "    print(classification_report(y_test, y_pred))\r\n",
        "    print(\"===================================\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "DecisionTreeClassifier\n              precision    recall  f1-score   support\n\n           0       0.30      0.30      0.30       417\n           1       0.85      0.84      0.85      1897\n\n    accuracy                           0.75      2314\n   macro avg       0.57      0.57      0.57      2314\nweighted avg       0.75      0.75      0.75      2314\n\n===================================\nRandomForestClassifier\n              precision    recall  f1-score   support\n\n           0       0.83      0.16      0.26       417\n           1       0.84      0.99      0.91      1897\n\n    accuracy                           0.84      2314\n   macro avg       0.84      0.57      0.59      2314\nweighted avg       0.84      0.84      0.79      2314\n\n===================================\nLGBMClassifier\n              precision    recall  f1-score   support\n\n           0       0.77      0.16      0.26       417\n           1       0.84      0.99      0.91      1897\n\n    accuracy                           0.84      2314\n   macro avg       0.81      0.57      0.58      2314\nweighted avg       0.83      0.84      0.79      2314\n\n===================================\nAdaBoostClassifier\n              precision    recall  f1-score   support\n\n           0       0.56      0.02      0.05       417\n           1       0.82      1.00      0.90      1897\n\n    accuracy                           0.82      2314\n   macro avg       0.69      0.51      0.47      2314\nweighted avg       0.77      0.82      0.75      2314\n\n===================================\nGradientBoostingClassifier\n              precision    recall  f1-score   support\n\n           0       0.78      0.11      0.19       417\n           1       0.84      0.99      0.91      1897\n\n    accuracy                           0.83      2314\n   macro avg       0.81      0.55      0.55      2314\nweighted avg       0.83      0.83      0.78      2314\n\n===================================\nLogisticRegression\n              precision    recall  f1-score   support\n\n           0       1.00      0.00      0.00       417\n           1       0.82      1.00      0.90      1897\n\n    accuracy                           0.82      2314\n   macro avg       0.91      0.50      0.45      2314\nweighted avg       0.85      0.82      0.74      2314\n\n===================================\nRidgeClassifier\n              precision    recall  f1-score   support\n\n           0       1.00      0.00      0.00       417\n           1       0.82      1.00      0.90      1897\n\n    accuracy                           0.82      2314\n   macro avg       0.91      0.50      0.45      2314\nweighted avg       0.85      0.82      0.74      2314\n\n===================================\nSGDClassifier\n              precision    recall  f1-score   support\n\n           0       1.00      0.00      0.00       417\n           1       0.82      1.00      0.90      1897\n\n    accuracy                           0.82      2314\n   macro avg       0.91      0.50      0.45      2314\nweighted avg       0.85      0.82      0.74      2314\n\n===================================\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}